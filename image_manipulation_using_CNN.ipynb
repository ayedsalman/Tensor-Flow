{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image manipulation using CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP3SUBIUPlkueijDsNGNqAV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayedsalman/Tensor-Flow/blob/master/image_manipulation_using_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrSvG3EPVZVa",
        "colab_type": "text"
      },
      "source": [
        "# Example of image detection using CNN\n",
        "This example use multiple layers CNN (including Maxpooling2D Pooling, Average Pooling, Dropout, data augmentation, and dense layer) to enhance accuracy of detection of a given image database. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfsFud5XU5UK",
        "colab_type": "code",
        "outputId": "6e83a495-898a-48b5-8615-77f31419fc7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#import needed classes\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,AveragePooling2D,Dropout,BatchNormalization,Activation\n",
        "from keras.models import Model,Input\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from math import ceil\n",
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvFoLtOdXMYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Unit(x,filters):\n",
        "    out = BatchNormalization()(x)\n",
        "    out = Activation(\"relu\")(out)\n",
        "    out = Conv2D(filters=filters, kernel_size=[3, 3], strides=[1, 1], padding=\"same\")(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "#Define the model\n",
        "\n",
        "\n",
        "def MiniModel(input_shape):\n",
        "    images = Input(input_shape)\n",
        "\n",
        "    net = Unit(images,64)\n",
        "    net = Unit(net,64)\n",
        "    net = Unit(net,64)\n",
        "    net = MaxPooling2D(pool_size=(2,2))(net)\n",
        "\n",
        "    net = Unit(net,128)\n",
        "    net = Unit(net,128)\n",
        "    net = Unit(net,128)\n",
        "    net = MaxPooling2D(pool_size=(2, 2))(net)\n",
        "\n",
        "    net = Unit(net,256)\n",
        "    net = Unit(net,256)\n",
        "    net = Unit(net,256)\n",
        "\n",
        "    net = Dropout(0.25)(net)\n",
        "    net = AveragePooling2D(pool_size=(8,8))(net)\n",
        "    net = Flatten()(net)\n",
        "    net = Dense(units=10,activation=\"softmax\")(net)\n",
        "\n",
        "    model = Model(inputs=images,outputs=net)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHKvrWSBXESJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e43778af-2879-4447-99ae-1d03371c70dc"
      },
      "source": [
        "#load the cifar10 dataset\n",
        "(train_x, train_y) , (test_x, test_y) = cifar10.load_data()\n",
        "\n",
        "#normalize the data\n",
        "train_x = train_x.astype('float32') / 255\n",
        "test_x = test_x.astype('float32') / 255\n",
        "\n",
        "#Subtract the mean image from both train and test set\n",
        "train_x = train_x - train_x.mean()\n",
        "test_x = test_x - test_x.mean()\n",
        "\n",
        "#Divide by the standard deviation\n",
        "train_x = train_x / train_x.std(axis=0)\n",
        "test_x = test_x / test_x.std(axis=0)\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(rotation_range=10,\n",
        "                             width_shift_range=5. / 32,\n",
        "                             height_shift_range=5. / 32,\n",
        "                             horizontal_flip=True)\n",
        "\n",
        "# Compute quantities required for featurewise normalization\n",
        "# (std, mean, and principal components if ZCA whitening is applied).\n",
        "datagen.fit(train_x)\n",
        "\n",
        "\n",
        "\n",
        "#Encode the labels to vectors\n",
        "train_y = keras.utils.to_categorical(train_y,10)\n",
        "test_y = keras.utils.to_categorical(test_y,10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAupjziiWcT2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "baea08c0-7a36-4f29-f36c-d4fc2a6bc809"
      },
      "source": [
        "#define a common unit\n",
        "\n",
        "\n",
        "input_shape = (32,32,3)\n",
        "model = MiniModel(input_shape)\n",
        "\n",
        "#Print a Summary of the model\n",
        "\n",
        "model.summary()\n",
        "#Specify the training components\n",
        "model.compile(optimizer=Adam(0.001),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "\n",
        "epochs = 5\n",
        "steps_per_epoch = ceil(5000/128)\n",
        "\n",
        "# Fit the model on the batches generated by datagen.flow().\n",
        "model.fit_generator(datagen.flow(train_x, train_y, batch_size=128),\n",
        "                    validation_data=[test_x,test_y],\n",
        "                    epochs=epochs,steps_per_epoch=steps_per_epoch, verbose=1, workers=4)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 32, 32, 3)         12        \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "average_pooling2d_2 (Average (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 1,926,934\n",
            "Trainable params: 1,924,752\n",
            "Non-trainable params: 2,182\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "40/40 [==============================] - 247s 6s/step - loss: 2.4869 - accuracy: 0.2016 - val_loss: 2.2745 - val_accuracy: 0.1458\n",
            "Epoch 2/5\n",
            "40/40 [==============================] - 250s 6s/step - loss: 1.8189 - accuracy: 0.2867 - val_loss: 2.7405 - val_accuracy: 0.1553\n",
            "Epoch 3/5\n",
            "40/40 [==============================] - 246s 6s/step - loss: 1.7840 - accuracy: 0.3184 - val_loss: 3.5274 - val_accuracy: 0.1180\n",
            "Epoch 4/5\n",
            "40/40 [==============================] - 246s 6s/step - loss: 1.7812 - accuracy: 0.3367 - val_loss: 3.2553 - val_accuracy: 0.1429\n",
            "Epoch 5/5\n",
            "40/40 [==============================] - 246s 6s/step - loss: 1.6745 - accuracy: 0.3709 - val_loss: 2.3340 - val_accuracy: 0.1828\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f5055a2c748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pbJAW3GTWeZA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c2cd065-c821-4fa5-c84f-348db2730c54"
      },
      "source": [
        "#Evaluate the accuracy of the test dataset\n",
        "accuracy = model.evaluate(x=test_x,y=test_y,batch_size=128)\n",
        "model.save(\"cifar10model.h5\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 75s 7ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzXbCa_dWVZG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1dcf602e-704d-4abe-e723-b782305f2aaf"
      },
      "source": [
        "print(accuracy)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.334030418777466, 0.18279999494552612]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}