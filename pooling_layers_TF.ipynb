{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pooling layers TF.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPa4Zy7StMiAy3ik62zObwe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayedsalman/Tensor-Flow/blob/master/pooling_layers_TF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjPh2it_98iy",
        "colab_type": "text"
      },
      "source": [
        "# Introduction to Pooling Layers for Convolutional Neural Networks\n",
        "**by Jason Brownlee** \n",
        "\n",
        "\n",
        "\n",
        "Convolutional layers in a convolutional neural network summarize the presence of features in an input image.\n",
        "\n",
        "A problem with the output feature maps is that they are sensitive to the location of the features in the input. One approach to address this sensitivity is to down sample the feature maps. This has the effect of making the resulting down sampled feature maps more robust to changes in the position of the feature in the image, referred to by the technical phrase “local translation invariance.”\n",
        "\n",
        "Pooling layers provide an approach to down sampling feature maps by summarizing the presence of features in patches of the feature map. Two common pooling methods are average pooling and max pooling that summarize the average presence of a feature and the most activated presence of a feature respectively.\n",
        "\n",
        "In this tutorial, you will discover how the pooling operation works and how to implement it in convolutional neural networks.\n",
        "\n",
        "After completing this tutorial, you will know:\n",
        "\n",
        "Pooling is required to down sample the detection of features in feature maps.\n",
        "How to calculate and implement average and maximum pooling in a convolutional neural network.\n",
        "How to use global pooling in a convolutional neural network.\n",
        "Discover how to build models for photo classification, object detection, face recognition, and more in my new computer vision book, with 30 step-by-step tutorials and full source code.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Pooling Layers**\n",
        "\n",
        "Convolutional layers in a convolutional neural network systematically apply learned filters to input images in order to create feature maps that summarize the presence of those features in the input.\n",
        "\n",
        "Convolutional layers prove very effective, and stacking convolutional layers in deep models allows layers close to the input to learn low-level features (e.g. lines) and layers deeper in the model to learn high-order or more abstract features, like shapes or specific objects.\n",
        "\n",
        "A limitation of the feature map output of convolutional layers is that they record the precise position of features in the input. This means that small movements in the position of the feature in the input image will result in a different feature map. This can happen with re-cropping, rotation, shifting, and other minor changes to the input image.\n",
        "\n",
        "A common approach to addressing this problem from signal processing is called down sampling. This is where a lower resolution version of an input signal is created that still contains the large or important structural elements, without the fine detail that may not be as useful to the task.\n",
        "\n",
        "Down sampling can be achieved with convolutional layers by changing the stride of the convolution across the image. A more robust and common approach is to use a pooling layer.\n",
        "\n",
        "**A pooling layer** is a new layer added after the convolutional layer. Specifically, after a nonlinearity (e.g. ReLU) has been applied to the feature maps output by a convolutional layer; for example the layers in a model may look as follows:\n",
        "\n",
        "1. Input Image\n",
        "2. Convolutional Layer\n",
        "3. Nonlinearity\n",
        "4. Pooling Layer\n",
        "\n",
        "The addition of a pooling layer after the convolutional layer is a common pattern used for ordering layers within a convolutional neural network that may be repeated one or more times in a given model.\n",
        "\n",
        "The pooling layer operates upon each feature map separately to create a new set of the same number of pooled feature maps.\n",
        "\n",
        "Pooling involves selecting a pooling operation, much like a filter to be applied to feature maps. The size of the pooling operation or filter is smaller than the size of the feature map; specifically, it is almost always 2×2 pixels applied with a stride of 2 pixels.\n",
        "\n",
        "This means that the pooling layer will always reduce the size of each feature map by a factor of 2, e.g. each dimension is halved, reducing the number of pixels or values in each feature map to one quarter the size. For example, a pooling layer applied to a feature map of 6×6 (36 pixels) will result in an output pooled feature map of 3×3 (9 pixels).\n",
        "\n",
        "The pooling operation is specified, rather than learned. Two common functions used in the pooling operation are:\n",
        "\n",
        "**Average Pooling:** Calculate the average value for each patch on the feature map.\n",
        "**Maximum Pooling (or Max Pooling):** Calculate the maximum value for each patch of the feature map.\n",
        "The result of using a pooling layer and creating down sampled or pooled feature maps is a summarized version of the features detected in the input. They are useful as small changes in the location of the feature in the input detected by the convolutional layer will result in a pooled feature map with the feature in the same location. This capability added by pooling is called the model’s invariance to local translation.\n",
        "\n",
        "In all cases, pooling helps to make the representation become approximately invariant to small translations of the input. Invariance to translation means that if we translate the input by a small amount, the values of most of the pooled outputs do not change.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDkHFNpH9qSM",
        "colab_type": "text"
      },
      "source": [
        "## The whole code of poolying example is shown here including both Max pooling and Average pooling layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1W4QSnG71vDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Full example of average/Max pooling\n",
        "from numpy import asarray\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import AveragePooling2D\n",
        "from keras.layers import MaxPooling2D\n",
        "\n",
        "# define input data\n",
        "data = [[0, 0, 0, 1, 1, 0, 0, 0],\n",
        "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
        "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
        "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
        "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
        "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
        "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
        "\t\t[0, 0, 0, 1, 1, 0, 0, 0]]\n",
        "data = asarray(data)\n",
        "data = data.reshape(1, 8, 8, 1)\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(1, (3,3), activation='relu', input_shape=(8, 8, 1)))\n",
        "model.add(AveragePooling2D())\n",
        "#model.add(MaxPooling2D())\n",
        "# summarize model\n",
        "model.summary()\n",
        "# define a vertical line detector\n",
        "detector = [[[[0]],[[1]],[[0]]],\n",
        "            [[[0]],[[1]],[[0]]],\n",
        "            [[[0]],[[1]],[[0]]]]\n",
        "weights = [asarray(detector), asarray([0.0])]\n",
        "# store the weights in the model\n",
        "model.set_weights(weights)\n",
        "# apply filter to input data\n",
        "yhat = model.predict(data)\n",
        "# enumerate rows\n",
        "for r in range(yhat.shape[1]):\n",
        "\t# print each column in the row\n",
        "\tprint([yhat[0,r,c,0] for c in range(yhat.shape[2])])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4A1Lg5dS9bv9",
        "colab_type": "text"
      },
      "source": [
        "## **`The next sections are trying to take the code peice by peice.`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozfGH-Kx1ygT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "87ee9628-b439-4e37-d411-c55c95d703df"
      },
      "source": [
        "%tensorflow_version 2.x  # this line is not required unless you are in a notebook\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `2.x  # this line is not required unless you are in a notebook`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfnIt9VR1bo1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define input data\n",
        "data = [[0, 0, 0, 1, 1, 0, 0, 0],\n",
        "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
        "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
        "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
        "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
        "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
        "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
        "\t\t[0, 0, 0, 1, 1, 0, 0, 0]]\n",
        "data = np.asarray(data)\n",
        "data = data.reshape(1, 8, 8, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcWWUj_u1o7n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(1, (3,3), activation='relu', input_shape=(8, 8, 1)))\n",
        "# summarize model\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4b2nwhc2zJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define a vertical line detector\n",
        "detector = [[[[0]],[[1]],[[0]]],\n",
        "            [[[0]],[[1]],[[0]]],\n",
        "            [[[0]],[[1]],[[0]]]]\n",
        "weights = [np.asarray(detector), np.asarray([0.0])]\n",
        "# store the weights in the model\n",
        "model.set_weights(weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka1paRz23Wld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# apply filter to input data\n",
        "yhat = model.predict(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdwZRVLK3pBk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "2d4452bf-8c28-4db5-8f63-fdc4269b2eed"
      },
      "source": [
        "# enumerate rows\n",
        "for r in range(yhat.shape[1]):\n",
        "\t# print each column in the row\n",
        "\tprint([yhat[0,r,c,0] for c in range(yhat.shape[2])])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0, 0.0, 3.0, 3.0, 0.0, 0.0]\n",
            "[0.0, 0.0, 3.0, 3.0, 0.0, 0.0]\n",
            "[0.0, 0.0, 3.0, 3.0, 0.0, 0.0]\n",
            "[0.0, 0.0, 3.0, 3.0, 0.0, 0.0]\n",
            "[0.0, 0.0, 3.0, 3.0, 0.0, 0.0]\n",
            "[0.0, 0.0, 3.0, 3.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3IQO8xb4-Ro",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "9377e124-d5ed-41b2-842a-fd759108d402"
      },
      "source": [
        "# create model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(1, (3,3), activation='relu', input_shape=(8, 8, 1)))\n",
        "model.add(layers.AveragePooling2D())\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 6, 6, 1)           10        \n",
            "_________________________________________________________________\n",
            "average_pooling2d_2 (Average (None, 3, 3, 1)           0         \n",
            "=================================================================\n",
            "Total params: 10\n",
            "Trainable params: 10\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}